---
title: "Verifying Panel Maps"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Verifying Panel Maps}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(conformr)
library(magrittr)
library(dplyr)
```

This vignettes provides additional detail on how Panel Maps are verified, and errors that might arises.

## Distinct code combinations

## Understanding the different transformation cases

```{r load_code_dict}

# import correspondence table
code_dict <- # conformr:::toy_AB$codes_BA
  dplyr::tribble(
    ~std_B, ~std_A,
    "A1", "x1111", # one-to-one
    "B2", "x2222", # many-to-one
    "B2", "x3333",
    "C3", "x4444", # one-to-many (4)
    "C4", "x4444",
    "C4", "x6666", # many-to-many
    "C5", "x4444",
    "C6", "x4444",
    "C7", "x5555", # one-to-many (3)
    "C8", "x5555",
    "C9", "x5555"
  )

# define code_in & code_out references
code_in <- sym("std_A")
code_out <- sym("std_B")

code_dict %>%
  select({{ code_in }}, {{ code_out }}) %>%
  arrange({{ code_in }}, {{ code_out }})
```

Now, let's do some data wrangling to see what kind of transformations will be included in our Panel Map:

```{r panel-map-with-cases}
panel_map_case <- code_dict %>%
  # work out where the values for each code_in will go
  group_by({{ code_in }}) %>%
  mutate(
    n_dest = n_distinct({{ code_out }}),
    split_in = 1 / n_dest
  ) %>%
  ungroup() %>%
  # work out how many values are going to each destination code_out
  group_by({{ code_out }}) %>%
  mutate(dest_size = n_distinct({{ code_in }})) %>%
  # label each case
  mutate(case_in_to_out = case_when(
    n_dest == 1 ~ "no split",
    n_dest != 1 ~ "split"
  )) %>%
  mutate(case_out_sum = case_when(
    dest_size == 1 ~ "no sum",
    dest_size != 1 ~ "sum up"
  )) %>%
  mutate(map_case = case_when(
    n_dest == 1 & dest_size == 1 ~ "1-to-1",
    n_dest != 1 & dest_size == 1 ~ "1-to-many",
    n_dest == 1 & dest_size != 1 ~ "many-to-1",
    n_dest != 1 & dest_size != 1 ~ "many-to-many"
  ))
# mutate(value_trans = case_when(map_case == "1-to-1" ~ "no change",
#                                map_case == "many-to-1" ~ "add up",
#                                map_case == "1-to-many" ~ "split",
#                                map_case == "many-to-many" ~ "split & add up"))
```

By summarising by the source classification, we can see what will happen to any values corresponding to a particular source code. Let us define the following input transformation cases:

-   1-to-1: values for these source codes are "transferred" over to single code in the destination classification
-   1-to-many: values in the source classification are "split" across multiple codes in the destination classification.

```{r summary_in_to_out}
# summary table of what happens to each value_in for every code_in
panel_map_case %>%
  mutate(dest_w_split = paste0(
    "", signif(split_in, 2) * 100,
    "%", " to ", {{ code_out }}
  )) %>%
  group_by({{ code_in }}, case_in_to_out) %>%
  summarise(
    value_in_split_to_out = paste(dest_w_split, collapse = ", "),
    .groups = "drop"
  ) %>%
  select({{ code_in }}, value_in_split_to_out)
```

Now pivoting our perspective to the target classification, we can see which destination codes have to "collect" values from multiple source codes. From here we can define following transformed output cases:

-   1-to-1: a single value from a single source code is "transferred" into a single destination code.
-   many-to-1: multiple values from different source codes are "transferred" and then "aggregated" into a single destination code.
-   many-to-many: multiple values from different source codes are "split" and or "transferred" and then "aggregated" across multiple destination codes.

```{r summary_out_by_in}
panel_map_case %>%
  mutate(source_w_split = paste0(
    {{ code_in }},
    " * [", signif(split_in, 2), "]"
  )) %>%
  group_by({{ code_out }}, case_out_sum) %>%
  summarise(
    value_out_sum = paste(source_w_split, collapse = " + "),
    .groups = "drop"
  ) %>%
  select({{ code_out }}, value_out_sum)
```

We can visualise part of the panel map using an alluvial diagram made using `[{ggalluvial}`](<https://cran.r-project.org/web/packages/ggalluvial/vignettes/ggalluvial.html>):

```{r alluvial-panel-map}
library(ggplot2)
library(ggalluvial)

# TODO: fix these cases to be exclusive
# TODO: color
panel_map_case %>%
  ggplot(
    .,
    aes(
      axis1 = {{ code_in }}, axis2 = {{ code_out }},
      y = n_dest
    )
  ) +
  scale_x_discrete(
    limits = c(deparse(code_in), deparse(code_out)),
    expand = c(.2, .05)
  ) +
  scale_fill_viridis_d() +
  xlab("Classification") +
  geom_alluvium(aes(fill = map_case), color = "black") +
  geom_stratum(style = "linear") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal()
# facet_grid(rows=vars(map_case))
#           scales = "free")
```

## Necessary and Sufficient Conditions

### Code Correspondence has no duplicates for making panel map

<!--# maybe move this to make_panel_maps.Rmd -->

-   otherwise you inadvertently lower the share going to non-duplicated destinations
-   `make_panel_mape_equal()` automatically clears duplicates

Consider the example below:

```{r, cake-setup}
cake_codes <- tribble(
  ~item, ~plate,
  "cake", "plate_1",
  "cake", "plate_2",
  "cake", "plate_3",
  "cream", "plate_3"
)

cake_data <- tribble(
  ~item, ~grams,
  "cake", 100,
  "cream", 15
)

cake_pm <- make_panel_map_equal(
  cake_codes,
  code_in = item,
  code_out = plate,
  .weights_to = "expected_split"
)
```

From the code dictionary, we would expect that each plate gets 1/3rd of the value associated with `cake`.

```{r, cake-expected-split, echo=FALSE}
cake_pm
```

However, notice what happens if we have a duplicate instruction:

```{r cake-dupe}
# duplicate the first instruction
dupe_codes <- bind_rows(cake_codes[1, ], cake_codes)

# now create an "equal" weight panel map using row counts
dupe_pm <-
  dupe_codes %>%
  group_by(item) %>%
  mutate(
    n_dest = n(), ## instead of n_distinct()
    weight = 1 / n_dest
  ) %>%
  group_by(item, plate) %>%
  summarise(item_weight = sum(weight), .groups = "drop")
```

`plate_1` has received an inflated share of the original cake data, while `plate_2` and `plate_2` received less than expected:

```{r, cake-pm-compare, echo=FALSE}
dupe_pm %>%
  left_join(cake_pm,
    by = c("item", "plate")
  )
```

Although we can produce a valid panel map, it doesn't reflect the instructions encoded in the code dictionary. For this reason, `make_panel_map_equal()` internally removes any duplicate `code_in` to `code_out` instructions using `dplyr::n_distinct()`.

```{r cake-distinct}
no_dupes_pm <- make_panel_map_equal(
  dupe_codes,
  code_in = item,
  code_out = plate,
  .weights_to = "item_weight"
)

# compare the panel maps
waldo::compare(
  x = dupe_pm,
  y = no_dupes_pm,
  x_arg = "dupe",
  y_arg = "distinct"
)
```

Now for completeness, let's use `no_dupes_pm` to produce the final "plating" of `cake_data`:

```{r}
cake_data

cake_on_plates <-
  use_panel_map(
    map = no_dupes_pm,
    data = cake_data,
    values_from = grams,
    from_code = item,
    to_code = plate,
    weights = item_weight,
    .suffix = ""
  )

cake_on_plates
```

### Weights in a panel map sum to one based on input code

<!--# TODO: INSERT DEMO CODE-->
