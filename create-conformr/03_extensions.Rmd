# Validation Helper Functions

## Panel Map

### Generate Equal Weights

In the most simple case, to make a panel map, we need only a correspondence between a source nomenclature (`std_A`) and target nomenclature (`std_B`), which doesn't have any duplicate rows.

#### Functions

This is a helper function for making a valid Panel Map with equal Mapping Weights from a concordance table.

```{r}
#' Helper to build equal split panel map
#'
#' Generate panel map using all *distinct* correspondences between two classifications.
#'
#' @param code_dict Data frame containing correspondence between source and destination codes
#' @param code_in Variable in `code_dict` containing source codes to convert from.
#' @param code_out Variable in `code_dict` containing destination codes to convert to.
#' @param .weights_to (optional) new column name for storing weights that will be applied to. The default name is `split_<<code_in>>`.
#' input values.
#'
#' @return Returns panel map as tibble
#' @export
#'
#' @examples
make_pm_equal <- function(code_dict, code_in, code_out, .weights_to = NULL){
  ## check and remove for duplicates
  n_dups <- sum(duplicated(code_dict))
  no_dup_links <- n_dups == 0
  if (!no_dup_links) {
    message("Removing duplicate code_in/code_out rows")
    code_dict <- code_dict |>
    dplyr::distinct({{code_in}}, {{code_out}})
  }

  ## make column name for weights
  .weights_to <- .weights_to %||% paste("split", deparse(substitute(code_in)), sep = "_")

  ## make panel map
  panel_map <- code_dict |>
    dplyr::group_by({{code_in}}) |>
    dplyr::mutate(n_dest = dplyr::n(),
                  !!.weights_to := 1 / n_dest) |>
    dplyr::ungroup() |>
    dplyr::select(-n_dest)

  return(panel_map)
}

#' @rdname make_pm_equal
#' @export
make_panel_map_equal <- make_pm_equal
```

Use this helper on the concordance table defined above:
```{r use-make-pm-equal}
make_pm_equal(codes_BA, std_A, std_B, "weights")
```

This function uses the `no_dup_links` flag to removes any duplicate instructions/links, to avoid assigning unequal shares to each target code/category (shown as `naive_share`):

```{r no-dup-links, message=FALSE}
library(dplyr)
codes <- tribble(~code_in, ~code_out,
                 "cake", "piece_01",
                 "cake", "piece_02",
                 "cake", "piece_03",
                 "cake", "piece_03" ## duplicated row
                 )

codes |>
  ## equal share by code_out
  mutate(equal_share = 1 / n_distinct(code_out)) |>
  ## without duplicates removed
  group_by(code_in) |>
  mutate("n_dest" = n(),
         weight := 1 / n_dest) |>
  ungroup() |>
  select(-n_dest) |>
  group_by(code_out) |>
  summarise(
    weights = paste(weight, collapse = "+"),
    naive_share = sum(weight),
    equal_share = unique(equal_share)
)
```

#### Tests
```{r testthat-make-pm-equal}
testthat::test_that(
  "make_pm_equal() works",
  {
    testthat::expect_identical(
      make_pm_equal(equal_pm$codes_BA, std_A, std_B, .weights_to = "weight"), equal_pm$pm_BA)
    testthat::expect_no_message(
      make_pm_equal(equal_pm$codes_BA, std_A, std_B, .weights_to = "weight"))
  }
)
testthat::test_that(
  "make_pm_equal() handles duplicate link correctly",
  {
    dup_codes_BA <- rbind(equal_pm$codes_BA, equal_pm$codes_BA[1, ])
    testthat::expect_message(
      make_pm_equal(dup_codes_BA, std_A, std_B)
    )
    testthat::expect_identical(
      make_pm_equal(dup_codes_BA, std_A, std_B, .weights_to = "weight"), equal_pm$pm_BA
    )
  }
)
```

### Get Bad Weights (TBC)

## Data Preparation for Concordance Transformation

Things that are checked for:

- missing values
- `code_in` and `value_in` columns

Probably good practice things, but too much hassle to check, so maybe put in vignette?

- `data_in` should only have one row/obs per `code_in`,
- ideally `data_in` has only the `code_in` and `values_in` columns... the rest get dropped (like with `dplyr::summarise()`)

# Workflows and Extensions

## Multiple Transformations

### Multi-Step Transformation (WIP)

Consider the task of transforming some data from classification A to C, and imagine you only have panel maps for the steps A-to-B and B-to-C. It is straightforward to chain these transformations together.

#### Stylized Code

#### Functions

#### Tests

### Multi-Group Transformations (WIP)

Consider the workflow where you want to apply the same transformation to multiple subsets of a larger dataframe. For example, trade data grouped by country.

### Mutli-Map-Group Transformations (WIP)

Consider datasets where you might want to apply variations of the same map to distinct subsets of a larger dataframe.

## Visualising Panel Map Representations

See [viz-panel-maps](https://cynthiahqy.github.io/viz-panel-maps/stylised-example.html#Define_and_visualise_concordances) for more:

### Panel Maps as Graphs

```{r}
pm_BA |> plt_pm_sigmoid(std_A, std_B, weight) +
  scale_fill_brewer(palette="RdPu", direction = -1)
```


## Custom Mapping Weights

Mapping weights could be based on:

- Reference data -- e.g. population share, past/future proportions
- Domain expertise
- ???

### Manual Design and Encoding

### Use Reference Proportions
