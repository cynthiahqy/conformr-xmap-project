---
title: "Using Crossmaps to Transform Data"
output:
  rmarkdown::html_vignette:
    toc: yes
bibliography: using-xmaps.bib
vignette: >
  %\VignetteIndexEntry{Using Crossmaps to Transform Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Nomenclature Variables and Datasets

```{r echo=FALSE}
state_data <- tibble::tribble(
                              ~State,    ~`Population (est. 30 Jun 2022)`,
                   "New South Wales", 8153600,
                          "Victoria", 6613700,
                        "Queensland", 5322100,
                   "South Australia", 1820500,
                 "Western Australia", 2785300,
                          "Tasmania",  571500,
                "Northern Territory",  250600,
      "Australian Capital Territory",  456700
)

total_pop_ex <- round(sum(state_data$`Population (est. 30 Jun 2022)`) / 10^6, 2)
```

A nomenclature variable is a set of name-value pairs, where the names correspond to categories or classes in a particular nomenclature, and the values can be considered part of the same aggregate pool. For instance, consider data on population by state in Australia[^1] shown below.

[^1]: Source: [Australian Bureau of Statistics](https://www.abs.gov.au/statistics/people/population/national-state-and-territory-population/jun-2022)

```{r echo=FALSE}
knitr::kable(state_data, caption = "Australian population by State (excl. Other Territories)")
```

The set of all name-value pairs of state/territory name and population estimate for a given time period form a nomenclature variable observation for Australia. The aggregate pool for which the values for each state belong is the total population of Australia.

### Tidy Nomenclature datasets

@wickham2007 introduces a division of dataset variables into two types: **identifier and measured variables:**

-   Identifier variables identify the unit that measurements are taken on.
-   Measured variables are values measured on the observation unit defined by the identifier variables.

Using the additional abstraction step of splitting measured variables into id-value pairs, we extend this taxonomy slightly to define a "tidy nomeclature data" format:

-   **Observational Unit Identifier Variables** are any identify variables used to index observational units. For example, country and year variables could be used to index population observations.
-   **Dimension Identifier Variables** identify the dimension, or set of dimensions, for the observation unit which measurements take place on.
-   **Measured Variables** contain values measured in a common "schematic?" unit. These variables combined with the associated dimension id variable form an observation on a particular dimension of the observational unit.

@wickham2014's **tidy data** (see [`vignette("tidy-data", package = "tidyr")`](https://tidyr.tidyverse.org/articles/tidy-data.html#defining)) format describes a standard way of structuring tabular datasets using the following data semantics:

> A dataset is a collection of **values**, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways. Every value belongs to a **variable** and an **observation**.

Under these semantics, every value in a tidy dataset belongs either to a observational unit identifier variable or a "simple" dimension variable. However, **nomenclature variables** are name-value pairs split across two columns, one for the nomenclature "dimension" identifier variable, and one for the associated measured value. In this case, every value belongs to a sub-dimension identifier variable, which forms part of a larger nomenclature dimension.

A **nomenclature dataset** consists of multiple observations of a single nomenclature variable. In a tidy nomenclature dataset, each observational unit should have the same number of rows across a shared nomenclature, which form the associated aggregate pool of value.

Hence for **tidy nomenclature data**:

1.  Every column is either a identifier variable, or part of a nomenclature name-value pair
2.  Every row is an observation on a nomenclature sub-dimension
3.  Every cell is a single value of an identifier variable, nomenclature node, or measured variable.

If we nest nomenclature data, we obtain a structure analogous to the standard tidy data format (@wickham2014):

1.  Every column is variable
2.  Every row is an observation
3.  Every cell is single value *or nested name-value set*.

Notice that nomenclature datasets blur the distinction between variable and value. For example, we could describe the above table as containing values of a `population` variable attached to the observational units of `state`, rather than a single observation of a `state-population` nomenclature variable (dimension-value pair) for the observational unit of "Australia".

However, the concept of a dimension identifier variable is useful for defining the data structure required to use crossmaps. Just as wider dataset formats are useful for data entry, and longer formats are more suited for analysis, the two-column nomenclature variable format is ideal for transforming or harmonising data between nomenclature.

The format is particularly suitable for cases where the original nomenclature:

a.  has sufficiently many category nodes that a wider format is difficult to work with,
b.  and/or will be transformed using a crossmap
c.  is expected to change relatively frequently (e.g. occupation or product classifications)
d.  is one layer of a larger hierarchical nomenclature

<!--- wide format vs. nomenclature format // makes sense in the context of transformation // nomenclature is sort of an observation id variable, except its not fixed the same way an observation id variable is --->

<!---- show examples --->

### Wild Caught Nomenclature Data

Let's tidy a wild caught dataset:

``` r
aus_pop <- readabs::download_abs_data_cube("national-state-and-territory-population", "31010do001_202206.xlsx")
```

```{r}
state_pop <- readxl::read_xlsx("data-raw/abs-population_2022.xlsx", sheet = "Table_3", range = "A6:D22")

state_pop
```

#### Issue 1: Multiple Nomenclature Variables in the Same Table

<!--- split into two tables --->

#### Issue 2: Observation Units split across columns (wide format)

<!--- pivot longer ---->

## Nomenclature Transformation

### Coverage requirement

The only strict requirement when applying a nomenclature crossmap to transform data is that the source nodes in the crossmap fully cover the nomenclature of the data to be transformed. This is equivalent to saying that the crossmap should contain transformation instructions for every single piece of data in the original dataset. Let's call this the Coverage requirement.

Depending on how the transformation is implemented, coverage mismatches can result in both explicit and implicit/hidden errors. In particular, having conformable matrix dimensions is not sufficient to avoid corrupting data unless you check that the indices match. This is a common issue with using matrices for data wrangling, so using database operations to apply the transformation is advised.

### No missing values

In addition to the coverage requirement, there are few additional conditions that should be checked to avoid any unexpected data loss or transformations:

Missing values should be dealt with prior to transformation as they can silently corrupt data in collapse or split transformations. Exactly how missing values should be treated will vary from dataset to dataset. This could involve replace the missing values with zeroes or some imputed values, or to remove them completely. For instance, in R, the function `sum()` takes the argument `na.rm` which when `TRUE` removes missing values from the sum. This is equivalent to treating missing values as `0` when collapsing multiple source values into a target node, and hence should be handled explicitly before applying the crossmap transformation.

The only exception to this is when the transformation is a one-to-one recode, such that missing values can be passed unmodified in to the target nomenclature.

### Tidy Original Dataset

Tidyness in the context of nomenclature variables requires that for each observation unit in the dataset, which can span multiple rows, there is only one row of values for each unique node in the original nomenclature. This ensures that only one numeric value is transformed for each source-target link. This is not a strict requirement, but avoids hidden aggregation across source nodes.

```{r}
## basically summarise numeric values into a single origin node.
origin_tidy_sub <- tibble::tribble(
  ~country, ~year, ~sector, ~subsector, ~output,
  "AU", 2012, "AGR", "FISH", 3983,
  "AU", 2012, "AGR", "LIVE", 432,
  "AU", 2013, "AGR", "FISH", 3983,
  "AU", 2013, "AGR", "LIVE", NA,
)

origin_tidy_sub
```

The above dataset is tidy for a crossmap with `subsector` source nodes, but would not be considered tidy for a crossmap with `sector` source nodes.

```{r}
origin_tidy_sec <- origin_tidy_sub |>
  dplyr::group_by(country, year, sector) |>
  dplyr::summarise(output = sum(output, na.rm = TRUE), .groups = "drop")

origin_tidy_sec
```

## Transformation via Mutating Joins

This vignette illustrates with simple examples how crossmaps can be used to complete recode, split and collapse transformation.

Notice that all crossmaps transformations can be decomposed into multiple "standard" transformation steps:

1.  recode node labels to target nomenclature

2.  mutate node values

3.  summarise mutated values by target node

#### Aggregation

Let's consider a simple case where we have some disaggregated population figures which we want to aggregate.

First, define a crossmap for the aggregation.

```{r}
library(xmap)

agg_map <- data.frame(ctr = "AU",
                      adm1 = c("AU-NSW", "AU-QLD", "AU-SA", "AU-TAS", "AU-VIC", "AU-WA", "AU-ACT", "AU-NT"),
                      link = 1) |>
  as_xmap_df(adm1, ctr, link)
```

Second, load in our state-level figures

```{r}
state_data <- tibble::tribble(
                              ~state,    ~adm1,    ~Pop,
                   "New South Wales", "AU-NSW", 8153600,
                          "Victoria", "AU-VIC", 6613700,
                        "Queensland", "AU-QLD", 5322100,
                   "South Australia",  "AU-SA", 1820500,
                 "Western Australia",  "AU-WA", 2785300,
                          "Tasmania", "AU-TAS",  571500,
                "Northern Territory",  "AU-NT",  250600,
      "Australian Capital Territory", "AU-ACT",  456700
)
```

Now, assuming your crossmap fully covers your data the transformation involves two steps:

1.  Joining the aggregate group to each row in `state_data`
2.  Summarising values for each group

```{r}
dplyr::left_join(state_data, agg_map, by = c("adm1")) |>
  dplyr::mutate(x_pop = Pop * link) |>
  dplyr::group_by(ctr) |>
  dplyr::summarise(agg_pop = sum(x_pop))
```

Or using `apply_xmap()` from the `conformr` package:

``` r
conformr::apply_xmap(data_in = state_data, xmap = agg_map,
                     in_codes = adm1, in_values = Pop,
                     out_codes = NULL, out_values = NULL)
```

which also checks that the nomenclature in `data_in` is fully covered by your `xmap` -- i.e. you don't lose any rows during the join.

#### Disaggregation

We can reverse the aggregation (assuming we retained appropriate weights) using:

``` r
apply_xmap(data_in = ctr_data, xmap = disagg_map, in_codes = ctr, in_values = Pop, out_codes = NULL, out_values = NULL)
```

#### Complex Maps

Using crossmaps for recoding, aggregation or disaggregation can seem a bit tedious given you can achieve the same transformation with some simple join and mutate statements, coupled with some ad-hoc validation. However, crossmpas are best suited for cases where you have multiple types of transformations being applied at once. In particular, they circumvent the need to count the number of observations after merging, and hence can insure against duplication and erroneous drops even in cases where it is difficult to calculate the expected number of post-transformations rows (i.e. many-to-many relations with both split and collapse transformations)

### Matrix (multiple variables at once)
